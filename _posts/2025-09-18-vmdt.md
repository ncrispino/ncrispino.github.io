---
layout: post
title:  "VMDT: Decoding the Trustworthiness of Video Foundation Models"
date:   2025-09-18 12:00:00 -0400
image: /vmdt.png
categories: research
author: "Nicholas Crispino"
authors: "Yujin Potter*, Zhun Wang*, Nicholas Crispino*, Kyle Montgomery*, Alexander Xiong*, Ethan Y. Chang, Francesco Pinto, Yuqi Chen, Rahul Gupta, Morteza Ziyadi, Christos Christodoulopoulos, Bo Li, Chenguang Wang, Dawn Song"
venue: in Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025).
arxiv: https://kylemontgomery1.github.io/assets/pdf/vmdt.pdf
code: https://github.com/sunblaze-ucb/VMDT
dataset: https://huggingface.co/datasets/mmfm-trust/V2T
---

VMDT is a benchmark for evaluating the trustworthiness of text-to-video (T2V) and video-to-text (V2T) models across five key dimensions: safety, hallucination, fairness, privacy, and adversarial robustness.